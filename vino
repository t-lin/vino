#!/usr/bin/env python
#
# Copyright 2014-2018 University of Toronto
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import os
import sys
import time
import pdb
import itertools

import paramiko
import subprocess

import topology2 as topology
import config2 as config
import novaclient.v1_1.client as nclient
import novaclient.v1_1.shell as nshell
from quantumclient.v2_0 import client as qclient
from quantumclient.quantum import v2_0 as quantumv20
from prettytable import PrettyTable

DELETE_CHOICE = ""


def add_secrules(nova, secgroup):
    """
    Creates secgroup rules
    parameters
        nova:-nova client object
    """
    rules = [("TCP", 22, 22), ("UDP", 4789, 4789), ("ICMP", -1, -1)]
    for rule in rules:
        try:
            nova.security_group_rules.create(secgroup.id, rule[0], rule[1], rule[2], "10.0.0.0/8")
        except Exception as e:
            if "rule already exists" not in e.message:
                raise

def create_node(node, node_name, nova, seclist, nics):
    print "Creating " + node_name

    #Get params
    user_name =  node.get('vm_user_name', config.vm_user_name)
    server_name = node.get('server', None)
    region_name = node.get('region', config.region_name)
    instance_name = node.get('name', config.instance_prefix + node_name)

    #Search for image and flavor
    flavor = nshell._find_flavor(nova, node.get('flavor', config.flavor_name))
    image = nshell._find_image(nova, node.get('image', config.image_name))

    # Pass hint for specific server if one was specified
    hints = {} if server_name is None else {"force_hosts": server_name}

    vm = nova.servers.create(instance_name, image, flavor, key_name=config.key_name,
                            security_groups=seclist, scheduler_hints=hints, nics=nics)
    return {"vm":vm, "status": 1, "name": node_name, "region": region_name,
                    "instance_name": instance_name, "user_name": user_name }

def pretty_print(nodes):
    ptable = PrettyTable(["VM UUID", "VM Name", "Region", "IPv4 Address"])

    for node_name, node in nodes.items():
        vm = node["vm"]
        ptable.add_row([vm.id, vm.name, node["region"], node["ip_addr"]])

    print ptable

def check_server_status(nodes):
    """
    Busy loops until each server either is up or fails

    VM status:
       -1-error
        0-no op
        1-build initiated
        2-ip address allocated
    """
    while True:
        in_progress = filter(lambda h: h["status"] == 1, nodes.values())
        if len(in_progress) == 0: return
        print "Waiting for {} servers".format(len(in_progress))

        for node in in_progress:
            n = node["vm"]
            n.get()
            if n.status == "ERROR":
                node["status"] = -1
                print "{} completed with error".format(node["name"])
            elif n.status == "ACTIVE":
                node["status"] = 2
                vm_net, vm_ip = n.networks.popitem()
                node["ip_addr"] = vm_ip[0]
                node["net"] = vm_net
                print "{} completed successfully".format(node["name"])
            time.sleep(6)

def error_check():
    #Check 1: Private key file exists
    try:
        with open(private_key_file, 'r') as private_key:
            pass
    except:
        print "Unable to open private key file at: '{}'".format(private_key_file)
        sys.exit(1)

# Performs ping test on newly booted VMs
# Also checks if OVS is installed, installing if necessary
def sanity_test(nodes):
    for n in nodes.values():
        # VM may not be up, loop until ping successful
        # TODO: Looping forever not a good idea, consider changing method (e.g. re-creating it)
        while True:
            print "Pinging {} at {}".format(n["name"], n["ip_addr"])
            try:
                output = subprocess.check_output(['ping', '-c 2', n["ip_addr"] ])
                print output
                break
            except Exception as e:
                print e
                print "Unable to ping. Trying again...."
                time.sleep(5)

        ssh = paramiko.SSHClient()
        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        while True:
            try:
                ssh.connect(n["ip_addr"], username=n["user_name"], key_filename=config.private_key_file)
                break
            except Exception as e:
                print e
                print "Unable to connect. Trying again...."
                time.sleep(5)

        time.sleep(3)

        # First, write hostname of VM to its /etc/hosts
        # Note the double escaping of forward-slash
        ssh.exec_command("sudo sed -E -i 's/(localhost)/\\1 '`hostname`'/g' /etc/hosts")
        time.sleep(1)

        # Check VM's internet connectivity
        stdin, stdout, stderr = ssh.exec_command("ping -c 2 www.google.ca")
        stdin.close()
        out = stdout.readlines()
        print "ping output is: %s" % (''.join(out))
        time.sleep(1)

        # Check if OVS is installed, install if it's not
        stdin, stdout, stderr = ssh.exec_command("dpkg -l | grep openvswitch")
        stdin.close()
        out = stdout.readlines()
        time.sleep(1)

        if not out: # dpkg -l didn't find anything
            print "Open vSwitch is not installed, installing now..."
            stdin, stdout, stderr = ssh.exec_command("sudo apt-get update && sudo apt-get install -y openvswitch-switch")
            stdin.close()

            # Wait for the command to terminate
            while not stdout.channel.exit_status_ready() or not stdout.channel.recv_ready() or \
                    not stderr.channel.exit_status_ready() or not stderr.channel.recv_ready():
                time.sleep(1)

        # Print OVS version
        print "Installed OVS version is:"
        stdin, stdout, stderr = ssh.exec_command("sudo ovs-vswitchd --version")
        stdin.close()
        out = stdout.readlines()
        time.sleep(1)
        if not out:
            print "No OVS installed, aborting..."
            sys.exit(1)
        else:
            print ''.join(out)

        ssh.close()

def _get_vm_id(node):
    vm_id = 0
    #Extract switch number
    if node.lower().startswith('sw'):
       vm_id = int(node.lower()[2:]) * 100
    #Extract host number
    elif node.lower().startswith('h'):
       vm_id = int(node.lower()[1:])
    return vm_id

def _get_vni(node1, node2):
    #Returns same VNI between two VMs
    vid1 = _get_vm_id(node1)
    vid2 = _get_vm_id(node2)

    vni =  max(vid1, vid2) + min(vid1, vid2)
    #print "%s --> %s : %s" %(node1, node2, vni)
    return vni

def setup_switches(hosts_dict, switches_dict):
    #Iterate over all switches
    for sw_name, sw_dict in switches_dict.items():
        sw_prop_map = topology.switches[sw_name] #The properties of the switch
        sw_topo_map = topology.topology[sw_name] #The list of interconnections
        print "Setting up {}".format(sw_name)

        #ssh to VM
        ssh = paramiko.SSHClient()
        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        ssh.connect(sw_dict["ip_addr"], username=sw_dict["user_name"], key_filename=config.private_key_file)
        time.sleep(3)

        # run the ovs commands
        bridge_name = sw_prop_map['bridge_name'] if 'bridge_name' in sw_prop_map else 'br1'
        ssh.exec_command("sudo ovs-vsctl add-br %s" % bridge_name)
        time.sleep(1)

        # Set OpenFlow version to 1.0 (TODO: Make this configurable in the future)
        ssh.exec_command("sudo ovs-vsctl set bridge %s protocols=OpenFlow10" % bridge_name)
        time.sleep(1)

        #Attach controller
        #Default for a OVS switch, is standalone mode
        contr_addr = sw_prop_map.get('contr_addr', topology.contr_addr)
        if contr_addr :
            ssh.exec_command("sudo ovs-vsctl set-controller %s tcp:%s" % (bridge_name, contr_addr))
            time.sleep(1)
            ssh.exec_command("sudo ovs-vsctl set-fail-mode %s secure" % bridge_name)
            time.sleep(1)
            ssh.exec_command("sudo ovs-vsctl set controller %s connection-mode=out-of-band"% bridge_name)
            time.sleep(1)

        if 'int_ip' in sw_prop_map:
            int_port, int_ip = sw_prop_map["int_ip"]
            ssh.exec_command("sudo ovs-vsctl add-port %s %s -- set interface %s type=internal" % (bridge_name, int_port, int_port))
            time.sleep(1)
            ssh.exec_command("mac=`sudo ovs-vsctl get interface %s mac_in_use`;sudo ovs-vsctl set interface %s mac=\"$mac\"" % (int_port, int_port));
            ssh.exec_command("sudo ifconfig %s %s/24 up" %(int_port, int_ip))
            time.sleep(1)

        node_ip = ''# the internal ip for use in the vxlan set up
        vni = 0 #The VNI- only VMs on the VNI can communicate

        #The iterate over nodes connected to this switch
        for node in sw_topo_map:
            # handle hosts
            if isinstance(node, tuple):
                vni = _get_vni(node[0], sw_name)
                node_ip = hosts_dict[node[0]]["ip_addr"]
            # handle switches
            else:
                vni = _get_vni(node, sw_name)
                node_ip = switches_dict[node]["ip_addr"]
            ssh.exec_command("sudo ovs-vsctl add-port %s vxlan%s -- set interface vxlan%s type=vxlan options:remote_ip=%s options:key=%s" % (bridge_name, vni, vni, node_ip, vni))
            time.sleep(1)
        ssh.close()

def setup_hosts(hosts_dict, switches_dict):
    for host_name, host_dict in hosts_dict.items():
        print "Setting up {}".format(host_name)
        ssh = paramiko.SSHClient()
        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        ssh.connect(host_dict["ip_addr"], username=host_dict["user_name"], key_filename=config.private_key_file)
        time.sleep(3)
        count = 0

        for sw_name, connections in topology.topology.items():
            for h in connections:
                if h[0] == host_name:
                    vxlan_ip = h[1]
                    bridge_name = h[2] if len(h) >= 3 else 'br%s' % count

                    # run the ovs commands
                    ssh.exec_command("sudo ovs-vsctl add-br %s" % bridge_name)
                    time.sleep(1)
                    ssh.exec_command("sudo ovs-vsctl add-port %s p%s -- set interface p%s type=internal" % (bridge_name,count, count))
                    time.sleep(1)
                    ssh.exec_command("mac=`sudo ovs-vsctl get interface p%s mac_in_use`;sudo ovs-vsctl set interface p%s mac=\"$mac\"" % (count, count));
                    time.sleep(1)
                    ssh.exec_command("sudo ifconfig p%s mtu 1400 %s/24 up" %(count, vxlan_ip))
                    time.sleep(1)

                    #get switch ip addr
                    switch_ip = switches_dict[sw_name]["ip_addr"]

                    vni = _get_vni(sw_name, host_name)
                    ssh.exec_command("sudo ovs-vsctl add-port %s vxlan%s -- set interface vxlan%s type=vxlan options:remote_ip=%s options:key=%s" %
                        (bridge_name,vni,vni,switch_ip, vni))
                    time.sleep(1)
                    count += 1
        ssh.close()

# Delete VMs passed in via oldVMList. All VMs should belong in the same region and tenant.
# Returns list of deleted VMs and VMs in oldVMList but not found by Nova.
# Both input and output lists have the following format:
#   [(VM UUID, VM NAME), (...), ...)
def delete_vms(nova, oldVMList):
    global DELETE_CHOICE

    DELETE_OPTIONS = ('yes', 'no', 'yesall', 'noall')

    oldVMIDs = [vm[0] for vm in oldVMList]
    region = nova.client.region_name
    deleted = []

    # First, let's fill 'deleted' with VMs which appear in the ViNO node file
    # but no longer exist. This may occur if a user manually deletes it.
    currVMs = nova.servers.list()
    currVMSet = set([(vm.id, vm.name) for vm in currVMs])
    deleted = list(set(oldVMList) - currVMSet)

    for s in currVMs:
        if s.id in oldVMIDs:
            while DELETE_CHOICE not in DELETE_OPTIONS:
                print "\nWARNING: Found a pre-existing VM created by ViNO (%s) in region %s. Delete it?" % (s.name, region)
                DELETE_CHOICE = raw_input("         [yes / no / yesall / noall] => ")
                DELETE_CHOICE = DELETE_CHOICE.lower()
                if DELETE_CHOICE not in DELETE_OPTIONS:
                    print "Invalid option, try again."

            if DELETE_CHOICE in ("yes", "yesall"):
                print "Deleting %s in %s" % (s.name, region)
                s.delete()
                deleted.append((s.id, s.name))

            if DELETE_CHOICE in ("yes", "no"):
                DELETE_CHOICE = "" # Reset for next loop

    return deleted

#walks through the topology dict and
#'completes' the topology, i.e.
#adds the bidirectionality info in the corresponding switch
#otherwise the vxlan tunnels are only one-way
#NOTE: This only works for singly-homed hosts
def complete_topology():
    #A list view of a map of interconnections
    #{sw_n: [connections], ...} -> [('sw_n', [connections] ), ...]
    topo_list = topology.topology.items()
    #sw_tuple == ('sw_n', [connection])
    for idx, sw_tuple in enumerate(topo_list):
        #pdb.set_trace()
        #The name, and connections of this switch
        this_sw_name, this_sw_conn = sw_tuple

        #The other switches
        other_sws = topo_list[:idx] + topo_list[idx+1:]

        #Iterate over the other switches
        for other_sw, conn in other_sws:
           for sw in conn:
               sw_name = sw[0] if type(sw) == tuple else sw

               #Update this_sw_conn since this_sw
               #appears in the dict of another switch
               if sw_name == this_sw_name and other_sw not in this_sw_conn:
                    this_sw_conn.append(other_sw)

    topo_map = dict(topo_list)

# Returns dictionary of existing VMs from ViNO node file
# Format of returned dict:
#   { "regionName" : [(VM UUID, VM NAME), (...), ...], ... }
# Default location for file: ~/.vino
#
# Can filter results via input parameter List 'relevantRegions'
#   - If this is None, then don't filter (i.e. return all)
def get_vino_node_file(relevantRegions = None):
    old_nodes = {}

    homePath = os.environ['HOME']
    try:
        nodeFile = open(homePath + '/.vino', 'r')
    except IOError as e:
        if "No such file or directory" not in e.strerror:
            raise
        else:
            # Create file
            nodeFile = open(homePath + '/.vino', 'w')
            nodeFile.close()
            return {}

    # Node file format:
    #   <REGION> <TENANT NAME> <VM UUID> <VM NAME>
    # NOTE: Currently we do not support multi-tenant overlay, the tenant name
    #       is just used to know which items to skip
    for line in nodeFile:
        try:
            reg, tenant, vmUUID, vmName = line.split()
            if relevantRegions is None or reg in relevantRegions:
                # Lists returned by ref, so no need to re-store
                vmList = old_nodes.setdefault(reg, [])
                if tenant == config.tenant_name:
                    vmList.append((vmUUID, vmName))
        except:
            import traceback; traceback.print_exc()
            print line
            sys.exit(1)

    nodeFile.close()
    return old_nodes

# Updates the ViNO node file (assumes it already exists)
# If delete = False (default), nodes from nodeList are appended
# If delete = True, nodes from nodeList are removed (if found in file)
#
# Assumes nodeList is format of [(VM UUID, VM NAME), (...), ...)
def update_vino_node_file(nodeList, region, delete = False):
    homePath = os.environ['HOME']

    try:
        if delete:
            nodeFile = open(homePath + '/.vino', 'r')
            lines = nodeFile.readlines()
            nodeFile.close()

            vmIDsToDelete = [vm[0] for vm in nodeList]
            nodeFile = open(homePath + '/.vino', 'w')
            for line in lines:
                reg, tenant, vmUUID, vmName = line.split()
                if vmUUID not in vmIDsToDelete:
                    nodeFile.write(line)

            nodeFile.close()
        else:
            # Append to file
            nodeFile = open(homePath + '/.vino', 'a')
            for node in nodeList:
                outLine = "%s %s %s %s\n" % (region, config.tenant_name, node[0], node[1])
                nodeFile.write(outLine)

            nodeFile.close()
    except:
        import traceback; traceback.print_exc()
        sys.exit(1)


def deployOverlay():
    complete_topology()
    regions = set()

    # Get list of regions from toplogy file
    for spec in topology.hosts.values():
        regions.add(spec['region'])

    for spec in topology.switches.values():
        regions.add(spec['region'])

    oldVMs = get_vino_node_file(regions)

    # Create a nova and neutron clients per region
    reg2nova = {}
    reg2neutron = {}
    for reg in regions:
        reg2nova[reg] = nclient.Client(config.username, config.password, config.tenant_name, config.auth_url, region_name=reg, no_cache=True)
        reg2neutron[reg] = qclient.Client(username=config.username, password=config.password, tenant_name=config.tenant_name, auth_url=config.auth_url, region_name=reg)

    #Delete any existing VMs
    print "\n===================="
    print "Checking for existing VMs from previous run(s)..."
    print "===================="
    for reg in oldVMs.keys():
        deleted = delete_vms(reg2nova[reg], oldVMs[reg])
        update_vino_node_file(deleted, reg, delete = True)

    print "Done check for old VMs."

    print "\n===================="
    print "Creating VMs for topology..."
    print "===================="
    hosts = {} #map of host name to host dict
    switches = {} #map of switch name to switch dict
    for reg in regions:
        nova = reg2nova[reg]
        neutron = reg2neutron[reg]

        # Create security group if it doesn't exist, then populate it
        seclist = [config.sec_group_name]
        try:
            secgroup = nshell._get_secgroup(nova, config.sec_group_name)
        except Exception as e:
            if "not found" in e.message:
                print "Security group does not exist, creating..."
                secgroup = nova.security_groups.create(config.sec_group_name, "For ViNO")
            else:
                raise
        else:
            add_secrules(nova, secgroup)

        #nic
        network_resource = quantumv20.find_resourceid_by_name_or_id(neutron, 'network', config.tenant_name+'-net')
        nic = {'net-id': network_resource, 'v4-fixed-ip': None}
        nics = [nic]

        for node_name, node in topology.hosts.items():
            if reg == node.get('region', config.region_name):
                vm_dict = create_node(node, node_name, nova, seclist, nics)
                vm_dict["network_id"] = network_resource
                hosts[node_name] = vm_dict
                update_vino_node_file([(vm_dict["vm"].id, vm_dict["instance_name"])], reg)

        for node_name, node in topology.switches.items():
            if reg == node.get('region', config.region_name):
                vm_dict = create_node(node, node_name, nova, seclist, nics)
                vm_dict["network_id"] = network_resource
                switches[node_name] = vm_dict
                update_vino_node_file([(vm_dict["vm"].id, vm_dict["instance_name"])], reg)

    nodes = dict(hosts.items() + switches.items()) #Joint dict of all nodes

    print "\n===================="
    print "Checking status of VMs..."
    print "===================="
    check_server_status(nodes) #Returns when all servers are completed
    sanity_test(nodes) #Performs ping test on newly booted VMs and checks if OVS is installed

    print "\n===================="
    print "Setting up overlay topology..."
    print "===================="
    setup_switches(hosts, switches)
    setup_hosts(hosts, switches)

    print "\n===================="
    print "Topology nodes information:"
    print "===================="
    pretty_print(nodes)  #Pretty table

    print "\nPlease log into your VMs and verify the overlay connectivity"
    return


def cleanupOverlay():
    # Read file to find any existing VMs
    oldVMs = get_vino_node_file()
    regions = oldVMs.keys()

    # Create a nova and neutron clients per region
    reg2nova = {}
    for reg in regions:
        reg2nova[reg] = nclient.Client(config.username, config.password, config.tenant_name, config.auth_url, region_name=reg, no_cache=True)

    #Delete any existing VMs
    print "===================="
    print "Checking for existing VMs from previous run(s)..."
    print "===================="
    for reg in oldVMs.keys():
        deleted = delete_vms(reg2nova[reg], oldVMs[reg])
        update_vino_node_file(deleted, reg, delete = True)

    print "Done cleanup of old VMs."

    return


def listOverlay():
    # Read file to find any existing VMs
    oldVMs = get_vino_node_file()
    regions = oldVMs.keys()

    # Create a nova and neutron clients per region
    reg2nova = {}
    for reg in regions:
        reg2nova[reg] = nclient.Client(config.username, config.password, config.tenant_name, config.auth_url, region_name=reg, no_cache=True)

    ptable = PrettyTable(["VM UUID", "VM Name", "Region", "IPv4 Address"])

    print "===================="
    print "Checking for existing VMs from previous run(s)..."
    print "===================="
    for reg, nodeList in oldVMs.items():
        vmIDs = [vm[0] for vm in nodeList]
        nova = reg2nova[reg]
        servers = nova.servers.list()

        for serv in servers:
            if serv.id in vmIDs:
                ipv4_addr = serv.networks.popitem()[1][0] # Assumes VM has 1 interface
                ptable.add_row([serv.id, serv.name, reg, ipv4_addr])

    if ptable._rows:
        print ptable
    else:
        print "None found"


def printHelp():
    print "Usage: ./vino [subcommand]"
    print "\tTo print this help message again, run: ./vino help"
    print "\tTo deploy a topology, run: ./vino deploy"
    print "\t  - Note: Deploy will call 'cleanup' on regions within the topology file"
    print "\tTo list VMs from all past deployments, run: ./vino list"
    print "\tTo clean up old topology nodes, run: ./vino cleanup"
    return

if __name__ == "__main__":
    SUBCOMMANDS = ('help', 'deploy', 'list', 'cleanup')

    if len(sys.argv) > 2:
        print "ERROR: Incorrect # of args"
        print
        printHelp()
        sys.exit();
    else:
        if len(sys.argv) == 2:
            if sys.argv[1] not in SUBCOMMANDS:
                print "ERROR: Unknown subcommand argument."
                print "       Currently subaccepted commands are: %s" % str(SUBCOMMANDS).strip('()')
                print
                printHelp()
                sys.exit();

    if len(sys.argv) == 1:
        # Called with no arguments
        printHelp()
    elif len(sys.argv) == 2:
        if sys.argv[1] == "help":
            printHelp()
        elif sys.argv[1] == "deploy":
            deployOverlay()
        elif sys.argv[1] == "list":
            listOverlay()
        elif sys.argv[1] == "cleanup":
            cleanupOverlay()

    sys.exit();
